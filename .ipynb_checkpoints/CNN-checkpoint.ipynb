{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeac99e-452c-465d-aa34-da4e2cc094c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4709c197-f160-4049-88cb-9a8d887725c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 100\n",
    "batch_train_size = 16\n",
    "batch_size = 15\n",
    "initial_learning_rate = 1.5e-4\n",
    "l2_regularize = 1.5e-5\n",
    "l1_regularize = 1e-6\n",
    "\n",
    "# Directories\n",
    "root = 'C:/Users/kahny/ML Model'\n",
    "train_dir = os.path.join(root, 'Train_Resized/')\n",
    "val_dir = os.path.join(root, 'Validate_Resized/')\n",
    "test_dir = os.path.join(root, 'Test_Resized/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa99f12-1e1c-4244-80bb-7b31d1e860fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_gen_w_aug(train_parent_directory, validate_parent_directory, test_parent_directory):\n",
    "    train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                                       rotation_range=45,\n",
    "                                       zoom_range=0.3,\n",
    "                                       width_shift_range=0.3,\n",
    "                                       height_shift_range=0.3,\n",
    "                                       shear_range=0.3,\n",
    "                                       horizontal_flip=True,\n",
    "                                       fill_mode='nearest')\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "    val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(train_parent_directory,\n",
    "                                                        target_size=(75, 75),\n",
    "                                                        batch_size=batch_train_size,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        shuffle=True)\n",
    "\n",
    "    val_generator = val_datagen.flow_from_directory(validate_parent_directory,\n",
    "                                                    target_size=(75, 75),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=False)\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(test_parent_directory,\n",
    "                                                      target_size=(75, 75),\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      class_mode='categorical',\n",
    "                                                      shuffle=False)\n",
    "\n",
    "    return train_generator, val_generator, test_generator\n",
    "\n",
    "train_generator, validation_generator, test_generator = image_gen_w_aug(train_dir, val_dir, test_dir)\n",
    "\n",
    "def build_sequential_inception(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    # First Inception-like block\n",
    "    model.add(Conv2D(32, (1, 1), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(48, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (5, 5), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Second Inception-like block\n",
    "    model.add(Conv2D(64, (1, 1), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(96, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (5, 5), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Third Inception-like block\n",
    "    model.add(Conv2D(128, (1, 1), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(192, (5, 5), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Fourth Inception-like block\n",
    "    model.add(Conv2D(128, (1, 1), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(192, (5, 5), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=l1_regularize, l2=l2_regularize)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=l1_regularize, l2=l2_regularize)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "input_shape = (75, 75, 3)\n",
    "model = build_sequential_inception(input_shape)\n",
    "\n",
    "class CustomStopper(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_acc = logs.get('accuracy')\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        if train_acc is not None and val_acc is not None:\n",
    "            if train_acc >= 0.96 and val_acc >= 0.96:\n",
    "                print(\"Stopping training as both training and validation accuracy have reached 96%.\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=initial_learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "custom_stopper = CustomStopper()\n",
    "\n",
    "# Function to convert DirectoryIterator to tf.data.Dataset\n",
    "def generator_to_dataset(generator):\n",
    "    output_signature = (\n",
    "        tf.TensorSpec(shape=(None, 75, 75, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 3), dtype=tf.float32)\n",
    "    )\n",
    "    def generator_function():\n",
    "        for batch in generator:\n",
    "            yield batch\n",
    "    return tf.data.Dataset.from_generator(generator_function, output_signature=output_signature)\n",
    "\n",
    "# Convert the generators to tf.data.Dataset\n",
    "train_dataset = generator_to_dataset(train_generator).repeat()\n",
    "validation_dataset = generator_to_dataset(validation_generator).repeat()\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_dataset,\n",
    "        validation_steps=len(validation_generator),\n",
    "        callbacks=[reduce_lr, custom_stopper]  # Ensure custom_stopper is included here\n",
    "    )\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "\n",
    "training_accuracy = history.history['accuracy'][-1]\n",
    "validation_accuracy = history.history['val_accuracy'][-1]\n",
    "training_loss = history.history['loss'][-1]\n",
    "validation_loss = history.history['val_loss'][-1]\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(f\"Training Accuracy: {training_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy: {validation_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\\n\")\n",
    "print(f\"Training Loss: {training_loss:.4f}\")\n",
    "print(f\"Validation Loss: {validation_loss:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\\n\")\n",
    "print(f\"Learning Rate: {initial_learning_rate}\")\n",
    "print(f\"Epochs: {epochs}\")\n",
    "print(f\"Steps Per Epoch: {len(train_generator)}\")\n",
    "print(f\"Batch Size: {train_generator.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f76ff-20fc-43de-be51-ed5ae68e2d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a26c695-df57-4125-aa24-ef4cd677a367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
